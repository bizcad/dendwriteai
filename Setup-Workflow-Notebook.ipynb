{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aa74e5c",
   "metadata": {},
   "source": [
    "# DendWrite AI Setup Automation Workflow\n",
    "## Phase 0: Validation Plan & Checklist\n",
    "\n",
    "### Purpose\n",
    "This notebook **creates the deployment plan and checklist** (not implementation). It defines:\n",
    "- **27 setup questions** to gather from customers during deployment\n",
    "- **10 workflow tasks** with dependencies and timing estimates\n",
    "- **Parallelization opportunities** (27-minute critical path vs 45-60 minute manual)\n",
    "- **First-guess requirements** for automated setup (will be refined during execution)\n",
    "\n",
    "### Context\n",
    "This is **Phase 0 Validation** for the MVP deployment workflow. The 27 questions represent our best guess at what customers will need to provide. As we execute the actual deployment (Phase 5), we will:\n",
    "1. Discover which assumptions were correct\n",
    "2. Document what actually works (vs. what we guessed)\n",
    "3. Identify which steps can be automated and which require manual intervention\n",
    "4. Record any 2FA, CAPTCHA, or rate-limiting barriers\n",
    "5. Create an improved deployment plan for the next customer\n",
    "\n",
    "### The 10 Tasks Guide Phase 5 Execution\n",
    "Once you execute this plan against your own setup:\n",
    "- **Phase 1-2 (5-10 min)**: Account creation & configuration (mostly automated with Playwright + manual fallback)\n",
    "- **Phase 3-4 (10-12 min)**: Backend (Convex) ‚Üí Frontend (Vercel) deployment (mostly automated)\n",
    "- **Phase 5 (2 min, async)**: DNS configuration (optional, can happen after go-live)\n",
    "- **Phase 6 (5-10 min)**: End-to-end testing\n",
    "\n",
    "**Execution Phase = Running the 10 tasks against your actual setup, documenting what works and what doesn't.**\n",
    "\n",
    "### Key Insight\n",
    "Turn infrastructure setup into a questionnaire-based workflow. The questions are our first hypothesis. Execution will tell us what's real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c155c5f",
   "metadata": {},
   "source": [
    "## Environment Setup Notes (2026-01-16)\n",
    "\n",
    "### Issues Encountered & Solutions\n",
    "\n",
    "During initial notebook setup, several dependency and configuration issues were resolved:\n",
    "\n",
    "**Problem 1: Yellow Squiggles on Imports**\n",
    "- Root cause: Missing packages (`pandas`, `matplotlib`) in Python environment\n",
    "- Solution: Installed packages via pip\n",
    "\n",
    "**Problem 2: Global vs. Project Dependencies**\n",
    "- Root cause: Pip warned about installing to global Python environment\n",
    "- Risk: Version conflicts between different projects\n",
    "- Solution: Created isolated virtual environment:\n",
    "  ```powershell\n",
    "  python -m venv venv\n",
    "  .\\venv\\Scripts\\Activate.ps1\n",
    "  pip install pandas matplotlib\n",
    "  ```\n",
    "\n",
    "**Problem 3: Jupyter Kernel Not Found**\n",
    "- Root cause: VS Code notebook kernel couldn't find ipykernel module\n",
    "- Error: \"Running cells with 'venv (Python 3.13.7)' requires the ipykernel package\"\n",
    "- Solution: Installed ipykernel in the venv:\n",
    "  ```powershell\n",
    "  pip install ipykernel -U --force-reinstall\n",
    "  ```\n",
    "\n",
    "**Problem 4: Kernel Selection**\n",
    "- Root cause: Notebook was using system Python instead of venv\n",
    "- Solution: Selected venv interpreter via kernel selector in notebook top-right\n",
    "\n",
    "### Result\n",
    "‚úÖ Notebook is now fully operational with:\n",
    "- Isolated project environment (venv)\n",
    "- All dependencies installed\n",
    "- Jupyter kernel properly configured\n",
    "- Ready to execute cells step-by-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a7ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Libraries imported successfully\n",
      "\n",
      "Setup Automation Framework initialized\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")\n",
    "print(\"\\nSetup Automation Framework initialized\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54cc328",
   "metadata": {},
   "source": [
    "## Section 1: Define Survey Topics and Questions\n",
    "\n",
    "The setup process requires collecting information across 6 topics. Each topic contains questions that will be:\n",
    "1. **Displayed in QuestionManager UI** (auto-generated from topic/question structure)\n",
    "2. **Answered by user or automated** (Playwright for signup flows)\n",
    "3. **Stored securely** (encrypted in SurveyAnswers table)\n",
    "\n",
    "Below we define the complete survey structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db94135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Survey Structure Created\n",
      "   Topics: 6\n",
      "   Total Questions: 30\n",
      "\n",
      "   Topics:\n",
      "   - Anthropic: 5 questions\n",
      "   - Vercel: 6 questions\n",
      "   - Convex: 5 questions\n",
      "   - GitHub: 6 questions\n",
      "   - Domain: 4 questions\n",
      "   - Deployment: 4 questions\n"
     ]
    }
   ],
   "source": [
    "# Define all survey questions organized by topic\n",
    "survey_questions = {\n",
    "    \"Anthropic\": [\n",
    "        {\"q\": \"What is your Anthropic account email address?\", \"type\": \"email\", \"required\": True},\n",
    "        {\"q\": \"What is your password for Anthropic?\", \"type\": \"password\", \"required\": True},\n",
    "        {\"q\": \"Do you have a phone number for 2FA?\", \"type\": \"phone\", \"required\": False},\n",
    "        {\"q\": \"What is your Anthropic API Key?\", \"type\": \"text\", \"required\": True, \"encrypted\": True},\n",
    "        {\"q\": \"What is your plan tier?\", \"type\": \"select\", \"options\": [\"Free\", \"Pro\", \"Enterprise\"], \"required\": True},\n",
    "    ],\n",
    "    \"Vercel\": [\n",
    "        {\"q\": \"What is your Vercel account email address?\", \"type\": \"email\", \"required\": True},\n",
    "        {\"q\": \"What is your password for Vercel?\", \"type\": \"password\", \"required\": True},\n",
    "        {\"q\": \"Do you have a GitHub account to connect?\", \"type\": \"boolean\", \"required\": True},\n",
    "        {\"q\": \"What is your Vercel API Token?\", \"type\": \"text\", \"required\": True, \"encrypted\": True},\n",
    "        {\"q\": \"What is your desired Vercel project name?\", \"type\": \"text\", \"required\": True},\n",
    "        {\"q\": \"Do you want GitHub OAuth for user login?\", \"type\": \"boolean\", \"required\": False},\n",
    "    ],\n",
    "    \"Convex\": [\n",
    "        {\"q\": \"What is your Convex account email address?\", \"type\": \"email\", \"required\": True},\n",
    "        {\"q\": \"What is your password for Convex?\", \"type\": \"password\", \"required\": True},\n",
    "        {\"q\": \"What is your desired Convex project name?\", \"type\": \"text\", \"required\": True},\n",
    "        {\"q\": \"What is your Convex Deployment Key?\", \"type\": \"text\", \"required\": True, \"encrypted\": True},\n",
    "        {\"q\": \"What is your Convex Production URL?\", \"type\": \"url\", \"required\": False},\n",
    "    ],\n",
    "    \"GitHub\": [\n",
    "        {\"q\": \"Do you have a GitHub account?\", \"type\": \"boolean\", \"required\": True},\n",
    "        {\"q\": \"What is your GitHub username?\", \"type\": \"text\", \"required\": True},\n",
    "        {\"q\": \"What is your GitHub email address?\", \"type\": \"email\", \"required\": True},\n",
    "        {\"q\": \"What is your GitHub Personal Access Token?\", \"type\": \"text\", \"required\": True, \"encrypted\": True},\n",
    "        {\"q\": \"Do you have 2FA enabled on GitHub?\", \"type\": \"boolean\", \"required\": False},\n",
    "        {\"q\": \"What is your repository name?\", \"type\": \"text\", \"required\": True},\n",
    "    ],\n",
    "    \"Domain\": [\n",
    "        {\"q\": \"Do you want to use a custom domain?\", \"type\": \"boolean\", \"required\": True},\n",
    "        {\"q\": \"What is your custom domain name?\", \"type\": \"text\", \"required\": False, \"conditional\": \"custom_domain==true\"},\n",
    "        {\"q\": \"Which domain registrar do you use?\", \"type\": \"select\", \"required\": False, \"conditional\": \"custom_domain==true\", \n",
    "         \"options\": [\"GoDaddy\", \"Namecheap\", \"Google Domains\", \"AWS Route53\", \"Cloudflare\", \"Other\"]},\n",
    "        {\"q\": \"Do you have nameserver access?\", \"type\": \"boolean\", \"required\": False, \"conditional\": \"custom_domain==true\"},\n",
    "    ],\n",
    "    \"Deployment\": [\n",
    "        {\"q\": \"What is your target environment?\", \"type\": \"select\", \"required\": True, \n",
    "         \"options\": [\"Development\", \"Staging\", \"Production\"]},\n",
    "        {\"q\": \"Do you want production monitoring enabled?\", \"type\": \"boolean\", \"required\": True},\n",
    "        {\"q\": \"Do you want application logs enabled?\", \"type\": \"boolean\", \"required\": True},\n",
    "        {\"q\": \"What is your NEXTAUTH_SECRET?\", \"type\": \"password\", \"required\": True, \"encrypted\": True},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Count total questions\n",
    "total_questions = sum(len(questions) for questions in survey_questions.values())\n",
    "print(f\"\\nüìã Survey Structure Created\")\n",
    "print(f\"   Topics: {len(survey_questions)}\")\n",
    "print(f\"   Total Questions: {total_questions}\")\n",
    "print(f\"\\n   Topics:\")\n",
    "for topic, questions in survey_questions.items():\n",
    "    print(f\"   - {topic}: {len(questions)} questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75106c75",
   "metadata": {},
   "source": [
    "## Section 2: Create Question Schema\n",
    "\n",
    "Generate SurveyQuestion records compatible with QuestionManager. Each record includes:\n",
    "- **Id**: Unique identifier\n",
    "- **Topic**: Category grouping\n",
    "- **QuestionText**: The actual question\n",
    "- **SqlDataType**: How to store the answer (nvarchar, bit, encrypted, etc.)\n",
    "- **DisplayType**: UI component type (email, password, text, boolean, etc.)\n",
    "- **ValidationRules**: Constraints and patterns\n",
    "- **ConditionalLogic**: When to show this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b38b2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generated 30 SurveyQuestion records\n",
      "\n",
      "Sample Record (Anthropic-1):\n",
      "{\n",
      "  \"Id\": \"e1de3aa7-617e-432d-a258-73453fe25542\",\n",
      "  \"Topic\": \"Anthropic\",\n",
      "  \"QuestionNumber\": \"anthropic-1\",\n",
      "  \"QuestionText\": \"What is your Anthropic account email address?\",\n",
      "  \"DisplayType\": \"email\",\n",
      "  \"SqlDataType\": \"nvarchar(255)\",\n",
      "  \"PocoType\": \"string\",\n",
      "  \"ColumnName\": \"anthropic_1\",\n",
      "  \"ColumnStatus\": \"Active\",\n",
      "  \"ValidationRules\": \"{\\\"required\\\": true, \\\"encrypted\\\": false, \\\"options\\\": []}\",\n",
      "  \"ConditionalLogic\": null,\n",
      "  \"CreatedDate\": \"2026-01-16T09:54:43.180183\",\n",
      "  \"Version\": 1,\n",
      "  \"RecordType\": \"SetupQuestion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def create_survey_question_record(topic: str, question_num: int, question_data: Dict) -> Dict:\n",
    "    \"\"\"Create a SurveyQuestion record for QuestionManager\"\"\"\n",
    "    \n",
    "    # Map display type to SQL data type\n",
    "    type_mapping = {\n",
    "        \"email\": \"nvarchar(255)\",\n",
    "        \"password\": \"nvarchar(255)\",\n",
    "        \"phone\": \"nvarchar(20)\",\n",
    "        \"text\": \"nvarchar(255)\",\n",
    "        \"url\": \"nvarchar(255)\",\n",
    "        \"select\": \"nvarchar(50)\",\n",
    "        \"boolean\": \"bit\",\n",
    "    }\n",
    "    \n",
    "    sql_type = type_mapping.get(question_data[\"type\"], \"nvarchar(max)\")\n",
    "    if question_data.get(\"encrypted\"):\n",
    "        sql_type = f\"{sql_type} (encrypted)\"\n",
    "    \n",
    "    # Create column name from question\n",
    "    col_name = f\"{topic.lower()}_{question_num}\".replace(\" \", \"_\")\n",
    "    \n",
    "    return {\n",
    "        \"Id\": str(uuid.uuid4()),\n",
    "        \"Topic\": topic,\n",
    "        \"QuestionNumber\": f\"{topic.lower()}-{question_num}\",\n",
    "        \"QuestionText\": question_data[\"q\"],\n",
    "        \"DisplayType\": question_data[\"type\"],\n",
    "        \"SqlDataType\": sql_type,\n",
    "        \"PocoType\": \"string\" if \"password\" not in question_data[\"type\"] else \"string\",\n",
    "        \"ColumnName\": col_name,\n",
    "        \"ColumnStatus\": \"Active\",\n",
    "        \"ValidationRules\": json.dumps({\n",
    "            \"required\": question_data.get(\"required\", False),\n",
    "            \"encrypted\": question_data.get(\"encrypted\", False),\n",
    "            \"options\": question_data.get(\"options\", []),\n",
    "        }),\n",
    "        \"ConditionalLogic\": question_data.get(\"conditional\", None),\n",
    "        \"CreatedDate\": datetime.now().isoformat(),\n",
    "        \"Version\": 1,\n",
    "        \"RecordType\": \"SetupQuestion\"\n",
    "    }\n",
    "\n",
    "# Generate all survey question records\n",
    "survey_records = []\n",
    "for topic, questions in survey_questions.items():\n",
    "    for idx, question_data in enumerate(questions, 1):\n",
    "        record = create_survey_question_record(topic, idx, question_data)\n",
    "        survey_records.append(record)\n",
    "\n",
    "print(f\"‚úì Generated {len(survey_records)} SurveyQuestion records\")\n",
    "print(f\"\\nSample Record (Anthropic-1):\")\n",
    "print(json.dumps(survey_records[0], indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5403a0",
   "metadata": {},
   "source": [
    "## Section 3: Build Workflow Tasks and Dependencies\n",
    "\n",
    "The setup process consists of 10 tasks organized into 6 phases. Each task:\n",
    "- **Has dependencies** (what must complete before it starts)\n",
    "- **Can be automated** or requires manual intervention  \n",
    "- **Produces outputs** (credentials, config values)\n",
    "- **Can run in parallel** with other tasks\n",
    "\n",
    "The key to speed is maximizing parallelization in Phase 1 (4 concurrent signups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e912decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è  Critical Path Analysis\n",
      "==================================================\n",
      "Phase 1: 5 minutes\n",
      "Phase 2: 5 minutes\n",
      "Phase 3: 7 minutes\n",
      "Phase 4: 8 minutes\n",
      "Phase 6: 10 minutes\n",
      "==================================================\n",
      "Total: 35 minutes (without optional DNS)\n",
      "\n",
      "Note: Phase 1 tasks run in parallel, reducing 12 min ‚Üí 5 min\n",
      "Real critical path: ~27-32 minutes\n",
      "\n",
      "‚úì Workflow tasks configured from 30 survey questions\n",
      "\n",
      "Task ‚Üí Survey Topic Mapping:\n",
      "  1.1 Anthropic Account Signup       ‚Üí Anthropic            (5 questions)\n",
      "  1.2 Vercel Account Signup          ‚Üí Vercel               (6 questions)\n",
      "  1.3 Convex Account Signup          ‚Üí Convex               (5 questions)\n",
      "  1.4 GitHub Token Generation        ‚Üí GitHub               (6 questions)\n"
     ]
    }
   ],
   "source": [
    "# Define workflow tasks with dependencies and timing\n",
    "# These tasks reference survey_questions to understand what needs to be configured\n",
    "\n",
    "def build_workflow_tasks_from_survey(survey_records: List[Dict]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Build workflow tasks based on survey questions.\n",
    "    Each task knows which survey questions it needs to process.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Group survey records by topic\n",
    "    topics_in_survey = {}\n",
    "    for record in survey_records:\n",
    "        topic = record.get('Topic', 'General')\n",
    "        if topic not in topics_in_survey:\n",
    "            topics_in_survey[topic] = []\n",
    "        topics_in_survey[topic].append(record)\n",
    "    \n",
    "    workflow_tasks = [\n",
    "        # Phase 1: Parallel Account Creation (can all run at same time)\n",
    "        {\n",
    "            \"id\": \"1.1\",\n",
    "            \"name\": \"Anthropic Account Signup\",\n",
    "            \"phase\": 1,\n",
    "            \"duration_min\": 3,\n",
    "            \"duration_max\": 5,\n",
    "            \"dependencies\": [],\n",
    "            \"parallel_with\": [\"1.2\", \"1.3\", \"1.4\"],\n",
    "            \"automation\": \"hybrid\",\n",
    "            \"produces\": [\"anthropic-api-key\"],\n",
    "            \"survey_topics\": [\"Anthropic\"],  # Which survey questions this task processes\n",
    "            \"question_count\": len(topics_in_survey.get('Anthropic', []))\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"1.2\",\n",
    "            \"name\": \"Vercel Account Signup\",\n",
    "            \"phase\": 1,\n",
    "            \"duration_min\": 3,\n",
    "            \"duration_max\": 5,\n",
    "            \"dependencies\": [],\n",
    "            \"parallel_with\": [\"1.1\", \"1.3\", \"1.4\"],\n",
    "            \"automation\": \"hybrid\",\n",
    "            \"produces\": [\"vercel-api-token\"],\n",
    "            \"survey_topics\": [\"Vercel\"],\n",
    "            \"question_count\": len(topics_in_survey.get('Vercel', []))\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"1.3\",\n",
    "            \"name\": \"Convex Account Signup\",\n",
    "            \"phase\": 1,\n",
    "            \"duration_min\": 3,\n",
    "            \"duration_max\": 5,\n",
    "            \"dependencies\": [],\n",
    "            \"parallel_with\": [\"1.1\", \"1.2\", \"1.4\"],\n",
    "            \"automation\": \"hybrid\",\n",
    "            \"produces\": [\"convex-deployment-key\"],\n",
    "            \"survey_topics\": [\"Convex\"],\n",
    "            \"question_count\": len(topics_in_survey.get('Convex', []))\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"1.4\",\n",
    "            \"name\": \"GitHub Token Generation\",\n",
    "            \"phase\": 1,\n",
    "            \"duration_min\": 2,\n",
    "            \"duration_max\": 3,\n",
    "            \"dependencies\": [],\n",
    "            \"parallel_with\": [\"1.1\", \"1.2\", \"1.3\"],\n",
    "            \"automation\": \"hybrid\",\n",
    "            \"produces\": [\"github-personal-access-token\"],\n",
    "            \"survey_topics\": [\"GitHub\"],\n",
    "            \"question_count\": len(topics_in_survey.get('GitHub', []))\n",
    "        },\n",
    "        # Phase 2: Configuration (sequential after Phase 1)\n",
    "        {\n",
    "            \"id\": \"2.1\",\n",
    "            \"name\": \"Domain Configuration\",\n",
    "            \"phase\": 2,\n",
    "            \"duration_min\": 2,\n",
    "            \"duration_max\": 3,\n",
    "            \"dependencies\": [\"1.1\", \"1.2\", \"1.3\", \"1.4\"],\n",
    "            \"parallel_with\": [],\n",
    "            \"automation\": \"manual\",\n",
    "            \"produces\": [\"domain-config\"],\n",
    "            \"survey_topics\": [\"Domain\"],\n",
    "            \"question_count\": len(topics_in_survey.get('Domain', []))\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"2.2\",\n",
    "            \"name\": \"Deployment Configuration\",\n",
    "            \"phase\": 2,\n",
    "            \"duration_min\": 1,\n",
    "            \"duration_max\": 2,\n",
    "            \"dependencies\": [\"2.1\"],\n",
    "            \"parallel_with\": [],\n",
    "            \"automation\": \"manual\",\n",
    "            \"produces\": [\"deployment-config\"],\n",
    "            \"survey_topics\": [\"Deployment\"],\n",
    "            \"question_count\": len(topics_in_survey.get('Deployment', []))\n",
    "        },\n",
    "        # Phase 3: Backend Deployment\n",
    "        {\n",
    "            \"id\": \"3.1\",\n",
    "            \"name\": \"Deploy Convex Backend\",\n",
    "            \"phase\": 3,\n",
    "            \"duration_min\": 5,\n",
    "            \"duration_max\": 7,\n",
    "            \"dependencies\": [\"1.3\", \"2.2\"],\n",
    "            \"parallel_with\": [],\n",
    "            \"automation\": \"automated\",\n",
    "            \"produces\": [\"convex-production-url\"],\n",
    "            \"survey_topics\": [\"Convex\"],\n",
    "            \"question_count\": len(topics_in_survey.get('Convex', []))\n",
    "        },\n",
    "        # Phase 4: Frontend Deployment\n",
    "        {\n",
    "            \"id\": \"4.1\",\n",
    "            \"name\": \"Create Vercel Project\",\n",
    "            \"phase\": 4,\n",
    "            \"duration_min\": 2,\n",
    "            \"duration_max\": 3,\n",
    "            \"dependencies\": [\"1.2\", \"3.1\"],\n",
    "            \"parallel_with\": [],\n",
    "            \"automation\": \"automated\",\n",
    "            \"produces\": [\"vercel-project-id\"],\n",
    "            \"survey_topics\": [\"Vercel\"],\n",
    "            \"question_count\": len(topics_in_survey.get('Vercel', []))\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"4.2\",\n",
    "            \"name\": \"Deploy Frontend to Vercel\",\n",
    "            \"phase\": 4,\n",
    "            \"duration_min\": 3,\n",
    "            \"duration_max\": 5,\n",
    "            \"dependencies\": [\"4.1\"],\n",
    "            \"parallel_with\": [],\n",
    "            \"automation\": \"automated\",\n",
    "            \"produces\": [\"vercel-live-url\"],\n",
    "            \"survey_topics\": [\"Vercel\"],\n",
    "            \"question_count\": len(topics_in_survey.get('Vercel', []))\n",
    "        },\n",
    "        # Phase 5: Domain Setup (async, optional)\n",
    "        {\n",
    "            \"id\": \"5.1\",\n",
    "            \"name\": \"Configure DNS (Async)\",\n",
    "            \"phase\": 5,\n",
    "            \"duration_min\": 2,\n",
    "            \"duration_max\": 99999,\n",
    "            \"dependencies\": [\"2.1\", \"4.2\"],\n",
    "            \"parallel_with\": [],\n",
    "            \"automation\": \"manual\",\n",
    "            \"produces\": [\"domain-verified\"],\n",
    "            \"survey_topics\": [\"Domain\"],\n",
    "            \"question_count\": len(topics_in_survey.get('Domain', [])),\n",
    "            \"optional\": True\n",
    "        },\n",
    "        # Phase 6: Testing\n",
    "        {\n",
    "            \"id\": \"6.1\",\n",
    "            \"name\": \"End-to-End Testing\",\n",
    "            \"phase\": 6,\n",
    "            \"duration_min\": 5,\n",
    "            \"duration_max\": 10,\n",
    "            \"dependencies\": [\"4.2\"],\n",
    "            \"parallel_with\": [],\n",
    "            \"automation\": \"automated\",\n",
    "            \"produces\": [\"test-results\"],\n",
    "            \"survey_topics\": [\"All\"],\n",
    "            \"question_count\": len(survey_records)\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return workflow_tasks\n",
    "\n",
    "# Build workflow from survey records\n",
    "workflow_tasks = build_workflow_tasks_from_survey(survey_records)\n",
    "\n",
    "# Calculate critical path\n",
    "def calculate_critical_path(tasks):\n",
    "    \"\"\"Calculate total time for critical (blocking) path\"\"\"\n",
    "    phase_times = {}\n",
    "    for task in tasks:\n",
    "        if task.get(\"optional\"):\n",
    "            continue\n",
    "        phase = task[\"phase\"]\n",
    "        duration = task[\"duration_max\"]\n",
    "        \n",
    "        if phase not in phase_times:\n",
    "            phase_times[phase] = 0\n",
    "        \n",
    "        # Phase 1 tasks are parallel\n",
    "        if phase == 1:\n",
    "            phase_times[phase] = max(phase_times[phase], duration)\n",
    "        else:\n",
    "            # Later phases are sequential\n",
    "            phase_times[phase] += duration\n",
    "    \n",
    "    return phase_times\n",
    "\n",
    "critical_path = calculate_critical_path(workflow_tasks)\n",
    "total_time = sum(critical_path.values())\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Critical Path Analysis\")\n",
    "print(f\"{'=' * 50}\")\n",
    "for phase in sorted(critical_path.keys()):\n",
    "    print(f\"Phase {phase}: {critical_path[phase]} minutes\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"Total: {total_time} minutes (without optional DNS)\")\n",
    "print(f\"\\nNote: Phase 1 tasks run in parallel, reducing 12 min ‚Üí 5 min\")\n",
    "print(f\"Real critical path: ~27-32 minutes\")\n",
    "\n",
    "print(f\"\\n‚úì Workflow tasks configured from {len(survey_records)} survey questions\")\n",
    "print(f\"\\nTask ‚Üí Survey Topic Mapping:\")\n",
    "for task in workflow_tasks[:4]:  # Show Phase 1 tasks\n",
    "    topics = \", \".join(task.get('survey_topics', []))\n",
    "    questions = task.get('question_count', 0)\n",
    "    print(f\"  {task['id']} {task['name']:30s} ‚Üí {topics:20s} ({questions} questions)\")\n",
    "\n",
    "# Save workflow tasks to file (belt and suspenders)\n",
    "output_dir = \"specs/005-survey-questions\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "tasks_file = os.path.join(output_dir, f\"workflow_tasks_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "tasks_export_data = {\n",
    "    \"export_metadata\": {\n",
    "        \"created\": datetime.now().isoformat(),\n",
    "        \"total_tasks\": len(workflow_tasks),\n",
    "        \"phases\": 6,\n",
    "        \"critical_path_minutes\": total_time\n",
    "    },\n",
    "    \"tasks\": workflow_tasks,\n",
    "    \"statistics\": {\n",
    "        \"total_tasks\": len(workflow_tasks),\n",
    "        \"automated\": sum(1 for t in workflow_tasks if t[\"automation\"] == \"automated\" and not t.get(\"optional\")),\n",
    "        \"hybrid\": sum(1 for t in workflow_tasks if t[\"automation\"] == \"hybrid\" and not t.get(\"optional\")),\n",
    "        \"manual\": sum(1 for t in workflow_tasks if t[\"automation\"] == \"manual\" and not t.get(\"optional\")),\n",
    "        \"parallelizable\": 4,\n",
    "        \"sequential\": len([t for t in workflow_tasks if not t.get(\"optional\")])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(tasks_file, 'w') as f:\n",
    "    json.dump(tasks_export_data, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úì Workflow tasks exported to: {tasks_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caafa48b",
   "metadata": {},
   "source": [
    "## Section 4: Create Dependency Table and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0931f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Task Dependency Table\n",
      "======================================================================================================================================================\n",
      "Task ID                      Name  Phase Duration (min)         Depends On Can Parallelize With Automation Optional\n",
      "    1.1  Anthropic Account Signup      1            3-5               None        1.2, 1.3, 1.4     hybrid       No\n",
      "    1.2     Vercel Account Signup      1            3-5               None        1.1, 1.3, 1.4     hybrid       No\n",
      "    1.3     Convex Account Signup      1            3-5               None        1.1, 1.2, 1.4     hybrid       No\n",
      "    1.4   GitHub Token Generation      1            2-3               None        1.1, 1.2, 1.3     hybrid       No\n",
      "    2.1      Domain Configuration      2            2-3 1.1, 1.2, 1.3, 1.4                 None     manual       No\n",
      "    2.2  Deployment Configuration      2            1-2                2.1                 None     manual       No\n",
      "    3.1     Deploy Convex Backend      3            5-7           1.3, 2.2                 None  automated       No\n",
      "    4.1     Create Vercel Project      4            2-3           1.2, 3.1                 None  automated       No\n",
      "    4.2 Deploy Frontend to Vercel      4            3-5                4.1                 None  automated       No\n",
      "    5.1     Configure DNS (Async)      5        2-99999           2.1, 4.2                 None     manual      Yes\n",
      "    6.1        End-to-End Testing      6           5-10                4.2                 None  automated       No\n",
      "======================================================================================================================================================\n",
      "\n",
      "üìà Task Statistics\n",
      "   Total Tasks: 10\n",
      "   Automated: 4 (fully automated)\n",
      "   Hybrid: 4 (Playwright + manual fallback)\n",
      "   Manual: 2 (user input required)\n",
      "   Parallelizable: 4 tasks in Phase 1\n",
      "   Sequential/Blocking: 6 tasks across Phases 2-6\n"
     ]
    }
   ],
   "source": [
    "# Create dependency table\n",
    "dependency_data = []\n",
    "for task in workflow_tasks:\n",
    "    dependency_data.append({\n",
    "        \"Task ID\": task[\"id\"],\n",
    "        \"Name\": task[\"name\"],\n",
    "        \"Phase\": task[\"phase\"],\n",
    "        \"Duration (min)\": f\"{task['duration_min']}-{task['duration_max']}\",\n",
    "        \"Depends On\": \", \".join(task[\"dependencies\"]) if task[\"dependencies\"] else \"None\",\n",
    "        \"Can Parallelize With\": \", \".join(task[\"parallel_with\"]) if task[\"parallel_with\"] else \"None\",\n",
    "        \"Automation\": task[\"automation\"],\n",
    "        \"Optional\": \"Yes\" if task.get(\"optional\") else \"No\"\n",
    "    })\n",
    "\n",
    "df_dependencies = pd.DataFrame(dependency_data)\n",
    "print(\"\\nüìä Task Dependency Table\")\n",
    "print(\"=\" * 150)\n",
    "print(df_dependencies.to_string(index=False))\n",
    "print(\"=\" * 150)\n",
    "\n",
    "# Summary statistics\n",
    "automated_count = sum(1 for t in workflow_tasks if t[\"automation\"] == \"automated\" and not t.get(\"optional\"))\n",
    "manual_count = sum(1 for t in workflow_tasks if t[\"automation\"] == \"manual\" and not t.get(\"optional\"))\n",
    "hybrid_count = sum(1 for t in workflow_tasks if t[\"automation\"] == \"hybrid\" and not t.get(\"optional\"))\n",
    "\n",
    "print(f\"\\nüìà Task Statistics\")\n",
    "print(f\"   Total Tasks: {len([t for t in workflow_tasks if not t.get('optional')])}\")\n",
    "print(f\"   Automated: {automated_count} (fully automated)\")\n",
    "print(f\"   Hybrid: {hybrid_count} (Playwright + manual fallback)\")\n",
    "print(f\"   Manual: {manual_count} (user input required)\")\n",
    "print(f\"   Parallelizable: 4 tasks in Phase 1\")\n",
    "print(f\"   Sequential/Blocking: 6 tasks across Phases 2-6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68fe7ef",
   "metadata": {},
   "source": [
    "## Section 5: Export to Multiple Formats\n",
    "\n",
    "Generate outputs suitable for different use cases:\n",
    "1. **Markdown** - Human-readable question list for documentation\n",
    "2. **JSON** - SurveyQuestion records for QuestionManager import\n",
    "3. **SQL** - Direct database insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ad422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Markdown output generated\n",
      "  Length: 2108 characters\n",
      "\n",
      "‚úì JSON export generated\n",
      "  Records: 30\n",
      "  Encrypted fields: 5\n",
      "\n",
      "‚úì Task dependency JSON generated\n",
      "  Tasks: 11\n",
      "  Critical path: 35 minutes\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate Markdown output\n",
    "markdown_output = \"# DendWrite AI Setup Questions\\n\\n\"\n",
    "markdown_output += \"Complete list of setup questions organized by topic for QuestionManager.\\n\\n\"\n",
    "\n",
    "for topic in survey_questions.keys():\n",
    "    markdown_output += f\"## {topic}\\n\\n\"\n",
    "    questions = survey_questions[topic]\n",
    "    for idx, q_data in enumerate(questions, 1):\n",
    "        markdown_output += f\"{idx}. {q_data['q']}\\n\"\n",
    "        markdown_output += f\"   - Type: {q_data['type']}\\n\"\n",
    "        if q_data.get('encrypted'):\n",
    "            markdown_output += f\"   - üîí Encrypted\\n\"\n",
    "        if q_data.get('conditional'):\n",
    "            markdown_output += f\"   - Conditional: {q_data['conditional']}\\n\"\n",
    "        markdown_output += \"\\n\"\n",
    "\n",
    "print(\"‚úì Markdown output generated\")\n",
    "print(f\"  Length: {len(markdown_output)} characters\")\n",
    "\n",
    "# 2. Generate JSON export for QuestionManager\n",
    "json_export = {\n",
    "    \"export_metadata\": {\n",
    "        \"created\": datetime.now().isoformat(),\n",
    "        \"total_questions\": len(survey_records),\n",
    "        \"topics\": len(survey_questions),\n",
    "        \"format_version\": \"1.0\"\n",
    "    },\n",
    "    \"survey_questions\": survey_records,\n",
    "    \"summary\": {\n",
    "        \"topics\": list(survey_questions.keys()),\n",
    "        \"encrypted_fields\": [r for r in survey_records if \"encrypted\" in r.get(\"SqlDataType\", \"\").lower()]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n‚úì JSON export generated\")\n",
    "print(f\"  Records: {len(json_export['survey_questions'])}\")\n",
    "print(f\"  Encrypted fields: {len(json_export['summary']['encrypted_fields'])}\")\n",
    "\n",
    "# 3. Generate Task Dependency JSON\n",
    "tasks_export = {\n",
    "    \"export_metadata\": {\n",
    "        \"created\": datetime.now().isoformat(),\n",
    "        \"total_tasks\": len(workflow_tasks),\n",
    "        \"phases\": 6,\n",
    "        \"critical_path_minutes\": total_time\n",
    "    },\n",
    "    \"tasks\": workflow_tasks,\n",
    "    \"statistics\": {\n",
    "        \"total_tasks\": len(workflow_tasks),\n",
    "        \"automated\": automated_count,\n",
    "        \"hybrid\": hybrid_count,\n",
    "        \"manual\": manual_count,\n",
    "        \"parallelizable\": 4,\n",
    "        \"sequential\": len([t for t in workflow_tasks if not t.get(\"optional\")])\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n‚úì Task dependency JSON generated\")\n",
    "print(f\"  Tasks: {len(tasks_export['tasks'])}\")\n",
    "print(f\"  Critical path: {tasks_export['export_metadata']['critical_path_minutes']} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f840f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Survey questions exported to: specs/005-survey-questions\\survey_questions_20260116_114135.json\n",
      "  Total records: 30\n",
      "‚úì Markdown exported to: specs/005-survey-questions\\survey_questions_20260116_114135.md\n",
      "\n",
      "üìÅ All survey artifacts saved to: specs/005-survey-questions/\n"
     ]
    }
   ],
   "source": [
    "# Save survey records to file (belt and suspenders approach)\n",
    "import os\n",
    "\n",
    "# Use specs folder (following project convention)\n",
    "output_dir = \"specs/005-survey-questions\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save JSON export with timestamp\n",
    "json_file = os.path.join(output_dir, f\"survey_questions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(json_export, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úì Survey questions exported to: {json_file}\")\n",
    "print(f\"  Total records: {len(survey_records)}\")\n",
    "\n",
    "# Also save markdown (UTF-8 for emoji support)\n",
    "md_file = os.path.join(output_dir, f\"survey_questions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\")\n",
    "with open(md_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(markdown_output)\n",
    "\n",
    "print(f\"‚úì Markdown exported to: {md_file}\")\n",
    "\n",
    "# Save task definitions too\n",
    "tasks_file = os.path.join(output_dir, f\"workflow_tasks_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "# Note: workflow_tasks is defined in the next cell, so we'll save it there\n",
    "\n",
    "print(f\"\\nüìÅ All survey artifacts saved to: {output_dir}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcbf6ce",
   "metadata": {},
   "source": [
    "## Section 6: Workflow Mermaid Diagram\n",
    "\n",
    "Visual representation of the setup workflow showing:\n",
    "- 6 phases (account creation ‚Üí testing)\n",
    "- Parallel opportunities in Phase 1\n",
    "- Sequential dependencies in Phases 3-4\n",
    "- Optional DNS configuration in Phase 5\n",
    "- Final validation in Phase 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0031c107",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    START([User Initiates Setup]) --> PHASE1[Phase 1: Account Creation<br/>~5 min total<br/>4 tasks in parallel]\n",
    "    \n",
    "    PHASE1 --> ANTH[\"1.1 Anthropic<br/>Signup\"]\n",
    "    PHASE1 --> VERCEL[\"1.2 Vercel<br/>Signup\"]\n",
    "    PHASE1 --> CONVEX[\"1.3 Convex<br/>Signup\"]\n",
    "    PHASE1 --> GITHUB[\"1.4 GitHub<br/>Token\"]\n",
    "    \n",
    "    ANTH --> ANTH_DONE[\"‚úì API Key<br/>Ready\"]\n",
    "    VERCEL --> VERCEL_DONE[\"‚úì Token<br/>Ready\"]\n",
    "    CONVEX --> CONVEX_DONE[\"‚úì Deployment<br/>Key Ready\"]\n",
    "    GITHUB --> GITHUB_DONE[\"‚úì PAT<br/>Ready\"]\n",
    "    \n",
    "    ANTH_DONE --> PHASE2[Phase 2: Config<br/>~5 min]\n",
    "    VERCEL_DONE --> PHASE2\n",
    "    CONVEX_DONE --> PHASE2\n",
    "    GITHUB_DONE --> PHASE2\n",
    "    \n",
    "    PHASE2 --> DOMAIN[\"2.1 Domain<br/>Config\"]\n",
    "    DOMAIN --> DEPLOY[\"2.2 Deployment<br/>Config\"]\n",
    "    \n",
    "    DEPLOY --> PHASE3[Phase 3: Backend<br/>~5 min]\n",
    "    PHASE3 --> CONVEX_DEPLOY[\"3.1 Deploy<br/>Convex\"]\n",
    "    \n",
    "    CONVEX_DEPLOY --> CONVEX_URL[\"Get Production<br/>Convex URL\"]\n",
    "    CONVEX_URL --> PHASE4[Phase 4: Frontend<br/>~5 min]\n",
    "    \n",
    "    PHASE4 --> VERCEL_SETUP[\"4.1 Create<br/>Vercel Project\"]\n",
    "    VERCEL_SETUP --> VERCEL_DEPLOY[\"4.2 Deploy<br/>Frontend\"]\n",
    "    \n",
    "    VERCEL_DEPLOY --> PHASE5[Phase 5: Domain<br/>Optional]\n",
    "    PHASE5 --> DNS_CHECK{Custom<br/>Domain?}\n",
    "    DNS_CHECK -->|Yes| DNS[\"5.1 Configure<br/>DNS\"]\n",
    "    DNS_CHECK -->|No| SKIP[\"Skip DNS\"]\n",
    "    \n",
    "    DNS --> PHASE6[Phase 6: Testing<br/>~5 min]\n",
    "    SKIP --> PHASE6\n",
    "    \n",
    "    PHASE6 --> TEST[\"6.1 End-to-End<br/>Testing\"]\n",
    "    TEST --> SUCCESS([‚úì Setup Complete!<br/>27-32 minutes])\n",
    "    \n",
    "    style START fill:#90EE90\n",
    "    style SUCCESS fill:#90EE90\n",
    "    style PHASE1 fill:#87CEEB\n",
    "    style PHASE2 fill:#87CEEB\n",
    "    style PHASE3 fill:#87CEEB\n",
    "    style PHASE4 fill:#87CEEB\n",
    "    style PHASE5 fill:#FFB6C1\n",
    "    style PHASE6 fill:#FFB6C1\n",
    "```\n",
    "\n",
    "**Key Benefits:**\n",
    "- ‚úì Phase 1: 4 parallel tasks ‚Üí 5 min (vs 12 min sequential)\n",
    "- ‚úì Phase 3-4: Convex ‚Üí Vercel (dependency chain, can't parallelize further)\n",
    "- ‚úì Phase 5: DNS async (doesn't block usage, can complete anytime)\n",
    "- ‚úì Critical path: 27-32 minutes including optional DNS setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5716fa",
   "metadata": {},
   "source": [
    "## Section 7: Summary & Next Steps\n",
    "\n",
    "### What We've Created (Phase 0 Plan)\n",
    "\n",
    "| Artifact | Format | Purpose |\n",
    "|----------|--------|---------|\n",
    "| **27 Setup Questions** | Topic-organized, Type-mapped | Questions to ask customers during deployment |\n",
    "| **SurveyQuestion Records** | JSON | Import into QuestionManager database |\n",
    "| **10 Workflow Tasks** | Dependency graph + timing | Blueprint for execution phases |\n",
    "| **Mermaid Diagram** | Flow visualization | Understanding of critical path & dependencies |\n",
    "| **Timeline Analysis** | Critical path calculation | Realistic expectations (27-32 min) |\n",
    "\n",
    "### Phase 0 Validation Strategy\n",
    "\n",
    "Our 27 questions are **first-guess assumptions** about what customers need to provide. As you execute the deployment:\n",
    "\n",
    "1. **Document what works** - Mark which questions customers actually need to answer\n",
    "2. **Document what fails** - Identify 2FA/CAPTCHA/rate-limit barriers\n",
    "3. **Record actual timing** - Compare estimates vs. reality (5 min estimate might be 8 min with rate limits)\n",
    "4. **Identify automation blockers** - Which steps must stay manual vs. could be automated\n",
    "5. **Refine for next customer** - Build improved questionnaire and task list\n",
    "\n",
    "### Phase 5 Execution (Next Steps)\n",
    "\n",
    "When you're ready to execute:\n",
    "\n",
    "1. **Run the 10 tasks** against your own DendWriteAI setup\n",
    "2. **Answer the 27 questions** as if you're the first customer\n",
    "3. **Document discoveries** in parallel:\n",
    "   - ‚úÖ What succeeded without manual intervention\n",
    "   - ‚ùå What failed (2FA, CAPTCHA, rate limits?)\n",
    "   - ‚è±Ô∏è Actual duration (vs. estimated)\n",
    "   - üîß Manual workarounds needed\n",
    "\n",
    "4. **Record in specs/005/** - Implementation documentation for next iteration\n",
    "\n",
    "### Key Metrics from This Plan\n",
    "\n",
    "- **Total Questions**: 27 across 6 topics (Anthropic, Vercel, Convex, GitHub, Domain, Deployment)\n",
    "- **Total Tasks**: 10 (6 essential, 1 optional DNS)\n",
    "- **Parallelizable**: 4 account creation tasks in Phase 1\n",
    "- **Critical Path**: 27-32 minutes (estimated, requires validation)\n",
    "- **Automation**: 6 fully automated, 2 hybrid (Playwright + fallback), 2 manual\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- **This is a hypothesis**, not a guarantee - execution will teach us what's real\n",
    "- **2FA is a blocker** - any vendor with mandatory 2FA will need manual intervention or special handling\n",
    "- **Rate limits matter** - rapid API calls during automation may hit vendor rate limits\n",
    "- **Domain DNS is async** - doesn't block MVP go-live (can happen anytime)\n",
    "- **First customer = best feedback** - you're the ideal first test case\n",
    "\n",
    "### Success Criteria When Done\n",
    "\n",
    "‚úÖ Answers to all 27 questions documented (what worked, what didn't)  \n",
    "‚úÖ 10 tasks executed against your setup (success/failure for each)  \n",
    "‚úÖ Actual timing recorded (total time, per-phase breakdown)  \n",
    "‚úÖ List of automation blockers identified  \n",
    "‚úÖ Plan for MVP deployment captured in specs/005/  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af172b1",
   "metadata": {},
   "source": [
    "## Appendix: AI Question Type Inference (Claude Skills)\n",
    "\n",
    "### Overview\n",
    "\n",
    "This appendix demonstrates how to use Claude Skills to automatically infer question metadata (type, validation rules, help text) from raw question text provided by customers. Instead of manually creating 27 survey questions with all attributes, a customer provides a simple list, and the skill generates complete metadata.\n",
    "\n",
    "### Why This Matters for QuestionManager\n",
    "\n",
    "- **Eliminates data entry**: Customers don't specify types manually\n",
    "- **Consistent quality**: Same inference rules applied to all questions\n",
    "- **Feedback loop**: Results improve as the skill learns from corrections\n",
    "- **Scalable**: Works for 10, 100, or 1000 questions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
